{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import operator as op\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88234"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Jessie/Desktop/MScBA/3. Spring quarter/Mining Big Datasets/Assignment#1/facebook_combined.txt', sep = ' ', header = None)\n",
    "df.columns = ['node1' , 'node2']\n",
    "fd = df[['node2', 'node1']]\n",
    "fd.columns = ['node1' , 'node2']\n",
    "undir = df.append(fd)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Common neighbors: FoF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[513, 400, 559, 373, 492, 500, 378, 436, 431, 514]\n",
      "[916, 1238, 1750, 1230, 1004, 1791, 1530, 1172, 1570, 1597]\n",
      "[2, 17, 140, 111, 137, 162, 19, 333, 44, 243]\n",
      "[46, 68, 99, 131, 175, 177, 225, 227, 278, 321]\n"
     ]
    }
   ],
   "source": [
    "def fof(network, nodeID, recommendations = 10):\n",
    "    \n",
    "    # Create a list of friends of the node we want to suggest friends to:\n",
    "    nodes_friends = list(network[network['node1'] == nodeID]['node2'])\n",
    "    \n",
    "    # Create a list of nodes that are not friends with the above node:\n",
    "    non_friends1 = network[network['node1'] != nodeID]\n",
    "    non_friends2 = non_friends1[non_friends1['node2'] != nodeID]\n",
    "    non_friends = list(set(non_friends2['node1']).symmetric_difference(set(nodes_friends)))\n",
    "   \n",
    "    nonfriends_friends = {}\n",
    "    nonfriends_count ={}\n",
    "\n",
    "    for i in range (0, len(non_friends)):\n",
    "        nonfriends_friends[non_friends[i]] = list(non_friends2[non_friends2['node2'] == non_friends[i]]['node1'])\n",
    "        nonfriends_count[non_friends[i]] = len(set(nodes_friends).intersection(set(nonfriends_friends[non_friends[i]])))\n",
    "\n",
    "    sorted_dict1 = sorted(sorted(nonfriends_count.items(), key = op.itemgetter(0)), key = op.itemgetter(1), reverse = True)[:recommendations]\n",
    "    return([i[0] for i in sorted_dict1])\n",
    "\n",
    "print(fof(undir, 107))\n",
    "print(fof(undir, 1126))\n",
    "print(fof(undir, 14))\n",
    "print(fof(undir, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Jaccard coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[513, 400, 492, 559, 373, 378, 436, 500, 431, 514]\n",
      "[916, 1750, 1230, 1530, 1004, 1238, 1172, 1791, 1789, 1597]\n",
      "[2, 140, 17, 162, 111, 333, 44, 137, 19, 243]\n",
      "[321, 11, 12, 15, 18, 37, 43, 74, 114, 209]\n"
     ]
    }
   ],
   "source": [
    "def jaccard_coef(network, nodeID, recommendations = 10):\n",
    "    nodes_friends = list(network[network['node1'] == nodeID]['node2'])\n",
    "    non_friends1 = network[network['node1'] != nodeID]\n",
    "    non_friends2 = non_friends1[non_friends1['node2'] != nodeID]\n",
    "    non_friends = list(set(non_friends2['node1']).symmetric_difference(set(nodes_friends)))\n",
    "   \n",
    "    nonfriends_friends = {}\n",
    "    nonfriends_count = {}\n",
    "\n",
    "    for i in range (0, len(non_friends)):\n",
    "        nonfriends_friends[non_friends[i]] = list(non_friends2[non_friends2['node2'] == non_friends[i]]['node1'])\n",
    "        nonfriends_count[non_friends[i]] = round(len(set(nodes_friends).intersection(set(nonfriends_friends[non_friends[i]]))) / len(set(nodes_friends).union(set(nonfriends_friends[non_friends[i]]))), 3)\n",
    "\n",
    "    sorted_dict2 = sorted(sorted(nonfriends_count.items(), key = op.itemgetter(0)), key = op.itemgetter(1), reverse = True)[:recommendations]\n",
    "    return([i[0] for i in sorted_dict2])\n",
    "\n",
    "print(jaccard_coef(undir, 107))\n",
    "print(jaccard_coef(undir, 1126))\n",
    "print(jaccard_coef(undir, 14))\n",
    "print(jaccard_coef(undir, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Adamic & Adar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[513, 400, 559, 500, 492, 373, 378, 436, 524, 514]\n",
      "[916, 1238, 1750, 1230, 1004, 1791, 1530, 1172, 1570, 1597]\n",
      "[2, 17, 140, 111, 162, 137, 333, 19, 44, 243]\n",
      "[46, 68, 99, 131, 175, 177, 225, 227, 278, 321]\n"
     ]
    }
   ],
   "source": [
    "def adamic_adar(network, nodeID, recommendations = 10):\n",
    "    nodes_friends = list(network[network['node1'] == nodeID]['node2'])\n",
    "    non_friends1 = network[network['node1'] != nodeID]\n",
    "    non_friends2 = non_friends1[non_friends1['node2'] != nodeID]\n",
    "    friends_friends = list(set(non_friends2['node1']).symmetric_difference(set(nodes_friends)))\n",
    "\n",
    "    G = nx.from_pandas_edgelist(network, source = 'node1', target = 'node2')\n",
    "    pairs = {}\n",
    "\n",
    "    for i in range(0, len(friends_friends)):\n",
    "        preds = nx.adamic_adar_index(G, [(nodeID, friends_friends[i])])\n",
    "        preds_list = list(preds)\n",
    "        pairs[preds_list[0][1]] = preds_list[0][2]\n",
    "        \n",
    "    sorted_dict3 = sorted(sorted(pairs.items(), key = op.itemgetter(0)), key = op.itemgetter(1), reverse = True)[:recommendations]\n",
    "    return([i[0] for i in sorted_dict3])\n",
    "\n",
    "print(adamic_adar(undir, 107))\n",
    "print(adamic_adar(undir, 1126))\n",
    "print(adamic_adar(undir, 14))\n",
    "print(adamic_adar(undir, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluation of the recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity percetange for each one of the 40 users is \n",
      "[20, 90, 60, 80, 90, 10, 30, 90, 70, 60, 80, 0, 50, 20, 70, 50, 10, 100, 10, 70, 70, 90, 40, 10, 90, 100, 30, 90, 20, 70, 60, 50, 70, 60, 60, 0, 20, 50, 90, 90]\n",
      "The average similarity between FoF and Jaccard Coefficient is 55.5%\n"
     ]
    }
   ],
   "source": [
    "nodes = np.arange(100, 4039, 100)\n",
    "\n",
    "# FoF vs Jaccard:\n",
    "fof_jaccard_similarity = []\n",
    "for i in range(0, len(nodes)):\n",
    "    ls_fof = fof(undir, nodes[i])\n",
    "    ls_jaccard = jaccard_coef(undir, nodes[i])\n",
    "    \n",
    "    sim_list = list(set(ls_fof).intersection(set(ls_jaccard)))\n",
    "    fof_jaccard_similarity.append(10 * len(sim_list))\n",
    "\n",
    "print(\"The similarity percentage for each one of the 40 users is \\n{}\".format(fof_jaccard_similarity))\n",
    "\n",
    "avg_fof_jaccard = sum(fof_jaccard_similarity)/len(fof_jaccard_similarity)\n",
    "print(\"The average similarity between FoF and Jaccard Coefficient is {}%\".format(avg_fof_jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity percetange for each one of the 40 users is \n",
      "[30, 80, 60, 80, 80, 10, 30, 90, 70, 70, 80, 30, 40, 20, 70, 50, 10, 100, 20, 70, 60, 90, 40, 20, 90, 100, 30, 90, 30, 70, 60, 50, 80, 60, 70, 0, 20, 50, 90, 90]\n",
      "The average similarity between FoF and Jaccard Coefficient is 57.0%\n"
     ]
    }
   ],
   "source": [
    "# Jaccard vs Adamic & Adar:\n",
    "jaccard_aa_similarity = []\n",
    "for i in range(0, len(nodes)):\n",
    "    ls_jaccard = jaccard_coef(undir, nodes[i])\n",
    "    ls_aa = adamic_adar(undir, nodes[i])\n",
    "    \n",
    "    sim_list = list(set(ls_aa).intersection(set(ls_jaccard)))\n",
    "    jaccard_aa_similarity.append(10 * len(sim_list))\n",
    "\n",
    "print(\"The similarity percentage for each one of the 40 users is \\n{}\".format(jaccard_aa_similarity))\n",
    "\n",
    "avg_jaccard_aa = sum(jaccard_aa_similarity)/len(jaccard_aa_similarity)\n",
    "print(\"The average similarity between FoF and Jaccard Coefficient is {}%\".format(avg_jaccard_aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity percetange for each one of the 40 users is \n",
      "[50, 90, 100, 100, 90, 100, 90, 100, 90, 80, 100, 30, 90, 100, 100, 100, 90, 100, 80, 100, 80, 100, 100, 60, 100, 100, 80, 100, 90, 90, 80, 100, 90, 100, 90, 90, 100, 100, 100, 100]\n",
      "The average similarity between FoF and Jaccard Coefficient is 90.75%\n"
     ]
    }
   ],
   "source": [
    "# Adamic & Adar vs FoF:\n",
    "fof_aa_similarity = []\n",
    "for i in range(0, len(nodes)):\n",
    "    ls_fof = fof(undir, nodes[i])\n",
    "    ls_aa = adamic_adar(undir, nodes[i])\n",
    "    \n",
    "    sim_list = list(set(ls_aa).intersection(set(ls_fof)))\n",
    "    fof_aa_similarity.append(10 * len(sim_list))\n",
    "\n",
    "print(\"The similarity percentage for each one of the 40 users is \\n{}\".format(fof_aa_similarity))\n",
    "\n",
    "avg_fof_aa = sum(fof_aa_similarity)/len(fof_aa_similarity)\n",
    "print(\"The average similarity between FoF and Jaccard Coefficient is {}%\".format(avg_fof_aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation:\n",
    "a = [] ; b = [] ; c = [] ; d = [] ; e = [] ; f = [] ; g = [] ; h = []\n",
    "\n",
    "seed = 0\n",
    "t1 = time.time()\n",
    "while len(a) <= 100:\n",
    "    temp = undir\n",
    "    remove_real = temp.sample(n = 1, random_state = seed)\n",
    "    temp = temp.drop(remove_real.index)\n",
    "    \n",
    "    f1_fof_list = fof(temp,remove_real.iloc[0,0]) # recommend for f1 with fof method    \n",
    "    f2_fof_list = fof(temp,remove_real.iloc[0,1]) # recommend for f2 with fof method    \n",
    "    f1_jaccard_list = jaccard_coef(temp,remove_real.iloc[0,0]) # recommend for f1 with jaccard        \n",
    "    f2_jaccard_list = jaccard_coef(temp,remove_real.iloc[0,1]) #recommend for f2 with jaccard        \n",
    "    f1_adam_list = adamic_adar(temp,remove_real.iloc[0,0]) # recommend for f1 with adam method    \n",
    "    f2_adam_list = adamic_adar(temp,remove_real.iloc[0,1]) #recommend for f2 with adam method\n",
    "    f1_resal_list = resource_allocation(temp, remove_real.iloc[0,0]) # recommend for f1 with adam method    \n",
    "    f2_resal_list = resource_allocation(temp, remove_real.iloc[0,1]) #recommend for f2 with adam method\n",
    "    \n",
    "    check1_fof = False\n",
    "    if remove_real.iloc[0, 1] in f1_fof_list:\n",
    "        check1_fof = True\n",
    "    \n",
    "    check2_fof = False\n",
    "    if remove_real.iloc[0, 0] in f2_fof_list:\n",
    "        check2_fof = True\n",
    "    \n",
    "    check1_jaccard = False\n",
    "    if remove_real.iloc[0, 1] in f1_jaccard_list:\n",
    "        check1_jaccard = True\n",
    "        \n",
    "    check2_jaccard = False\n",
    "    if remove_real.iloc[0, 0] in f2_jaccard_list:\n",
    "        check2_jaccard = True\n",
    "        \n",
    "    check1_adam = False\n",
    "    if remove_real.iloc[0, 1] in f1_adam_list:\n",
    "        check1_adam = True\n",
    "        \n",
    "    check2_adam = False\n",
    "    if remove_real.iloc[0, 0] in f2_adam_list:\n",
    "        check2_adam = True \n",
    "        \n",
    "    check1_resal = False\n",
    "    if remove_real.iloc[0, 1] in f1_resal_list:\n",
    "        check1_resal = True\n",
    "        \n",
    "    check2_resal = False\n",
    "    if remove_real.iloc[0, 0] in f2_resal_list:\n",
    "        check2_resal = True\n",
    "       \n",
    "    if (check1_fof & check2_fof & check1_jaccard & check2_jaccard & check1_adam & check2_adam & check1_resal & check2_resal):\n",
    "        a.append(f1_fof_list.index(remove_real.iloc[0,1]))\n",
    "        b.append(f2_fof_list.index(remove_real.iloc[0,0]))\n",
    "        c.append(f1_jaccard_list.index(remove_real.iloc[0,1]))\n",
    "        d.append(f2_jaccard_list.index(remove_real.iloc[0,0]))\n",
    "        e.append(f1_adam_list.index(remove_real.iloc[0,1]))\n",
    "        f.append(f2_adam_list.index(remove_real.iloc[0,0]))\n",
    "        g.append(f1_resal_list.index(remove_real.iloc[0,1]))\n",
    "        h.append(f2_resal_list.index(remove_real.iloc[0,0]))\n",
    "     \n",
    "    seed = seed + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rank for FoF is : 1.94\n",
      "Average Rank for Jaccard Coeff is : 2.33\n",
      "\n",
      "Average Rank for Adaric-Adam is : 1.85\n",
      "\n",
      "Average Rank for resource allocation is : 1.86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fof_avg = (sum(a)/len(a)+sum(b)/len(b))/2\n",
    "print(\"Average Rank for FoF is : {}\".format(round(fof_avg,2)))\n",
    "\n",
    "jac_avg = (sum(c)/len(c)+sum(d)/len(d))/2\n",
    "print(\"Average Rank for Jaccard Coeff is : {}\\n\".format(round(jac_avg,2)))\n",
    "\n",
    "aa_avg = (sum(e)/len(e)+sum(f)/len(f))/2\n",
    "print(\"Average Rank for Adaric-Adam is : {}\\n\".format(round(aa_avg,2)))\n",
    "\n",
    "resal_avg = (sum(g)/len(g)+sum(h)/len(h))/2\n",
    "print(\"Average Rank for resource allocation is : {}\\n\".format(round(resal_avg,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Assignment Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3263, 513, 400, 173, 500, 3278, 630, 465, 3290, 559]\n",
      "[916, 1238, 1750, 1230, 1004, 1791, 1172, 1570, 1530, 1597]\n",
      "[2, 17, 140, 111, 162, 333, 137, 19, 44, 243]\n",
      "[46, 68, 99, 131, 175, 177, 225, 227, 278, 321]\n"
     ]
    }
   ],
   "source": [
    "def resource_allocation(network, nodeID, recommendations = 10):\n",
    "    nodes_friends = list(network[network['node1'] == nodeID]['node2'])\n",
    "    non_friends1 = network[network['node1'] != nodeID]\n",
    "    non_friends2 = non_friends1[non_friends1['node2'] != nodeID]\n",
    "    friends_friends = list(set(non_friends2['node1']).symmetric_difference(set(nodes_friends)))\n",
    "\n",
    "    G = nx.from_pandas_edgelist(network, source = 'node1', target = 'node2')\n",
    "    pairs = {}\n",
    "\n",
    "    for i in range(0, len(friends_friends)):\n",
    "        preds = nx.resource_allocation_index(G, [(nodeID, friends_friends[i])])\n",
    "        preds_list = list(preds)\n",
    "        pairs[preds_list[0][1]] = preds_list[0][2]\n",
    "\n",
    "    sorted_dict4 = sorted(sorted(pairs.items(), key = op.itemgetter(0)), key = op.itemgetter(1), reverse = True)[:recommendations]\n",
    "    return([i[0] for i in sorted_dict4])\n",
    "\n",
    "print(resource_allocation(undir, 107))\n",
    "print(resource_allocation(undir, 1126))\n",
    "print(resource_allocation(undir, 14))\n",
    "print(resource_allocation(undir, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation:\n",
    "a = [] ; b = [] ; c = [] ; d = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    temp = undir\n",
    "    remove_real = temp.sample(n = 1, random_state = i)\n",
    "    temp = temp.drop(remove_real.index)\n",
    "    \n",
    "    f1_fof_list = fof(temp,remove_real.iloc[0,0]) # recommend for f1 with fof method    \n",
    "    f2_fof_list = fof(temp,remove_real.iloc[0,1]) # recommend for f2 with fof method    \n",
    "    f1_jaccard_list = jaccard_coef(temp,remove_real.iloc[0,0]) # recommend for f1 with jaccard        \n",
    "    f2_jaccard_list = jaccard_coef(temp,remove_real.iloc[0,1]) #recommend for f2 with jaccard        \n",
    "    f1_adam_list = adamic_adar(temp,remove_real.iloc[0,0]) # recommend for f1 with adam method    \n",
    "    f2_adam_list = adamic_adar(temp,remove_real.iloc[0,1]) #recommend for f2 with adam method\n",
    "    f1_resal_list = resource_allocation(temp, remove_real.iloc[0,0]) # recommend for f1 with adam method    \n",
    "    f2_resal_list = resource_allocation(temp, remove_real.iloc[0,1]) #recommend for f2 with adam method\n",
    "    \n",
    "    a.append(1) if remove_real.iloc[0, 1] in f1_fof_list else a.append(0)\n",
    "    \n",
    "    b.append(1) if remove_real.iloc[0, 0] in f2_fof_list else b.append(0)\n",
    "    \n",
    "    c.append(1) if remove_real.iloc[0, 1] in f1_jaccard_list else c.append(0) \n",
    "        \n",
    "    d.append(1) if remove_real.iloc[0, 0] in f2_jaccard_list else d.append(0)\n",
    "        \n",
    "    e.append(1) if remove_real.iloc[0, 1] in f1_adam_list else e.append(0)\n",
    "        \n",
    "    f.append(1) if remove_real.iloc[0, 0] in f2_adam_list else f.append(0)\n",
    "        \n",
    "    g.append(1) if remove_real.iloc[0, 1] in f1_resal_list else g.append(0)\n",
    "        \n",
    "    h.append(1) if remove_real.iloc[0, 0] in f2_resal_list else h.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((sum(a)/len(a) + sum(b)/len(b))/2)\n",
    "print((sum(c)/len(c) + sum(d)/len(d))/2)\n",
    "print((sum(e)/len(e) + sum(f)/len(f))/2)\n",
    "print((sum(g)/len(g) + sum(h)/len(h))/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
